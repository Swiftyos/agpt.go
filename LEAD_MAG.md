


## 1. The Analog / Pre‑AI Business

**Snapshot:**  
Mostly manual, spreadsheet‑driven, and still fighting fires just to keep day‑to‑day operations running.

**Typical criteria**

- **Data & systems**
    
    - Critical data lives in spreadsheets, email, or paper.
        
    - Different teams keep their own versions of the truth; no central database or data warehouse.
        
    - No API connections between systems; lots of copy‑paste.
        
- **AI usage**
    
    - No formal AI projects.
        
    - A few individuals might use ChatGPT/Copilot personally, but it’s not sanctioned or structured.
        
- **People & culture**
    
    - Leadership sees AI as “nice to have” or “not for our type of business.”
        
    - Little to no data or analytics capability in‑house.
        
- **Governance & compliance**
    
    - No policies around data use, security, or AI tools.
        

**What’s really going on**

- The **real blocker isn’t AI** – it’s basic digital/data readiness.
    
- Any AI project would immediately hit issues with missing data, inconsistent processes, and change fatigue.

### What to focus on next

- **Get your key processes out of email and paper.**  
    Choose 2–3 critical workflows (e.g. orders, jobs, invoices) and move them into simple, structured tools (CRM, ERP, ticketing, project systems).
    
- **Create a single source of truth for core data.**  
    Decide where “the real” customer, product, or asset data lives and stop duplicating it across random spreadsheets.
    
- **Standardise how data is captured.**  
    Define required fields, naming conventions, and who is responsible for keeping each dataset clean.
    
- **Fix obvious data issues in one area first.**  
    Clean duplicates, fill in missing key fields, and remove obsolete records in _one_ high‑value dataset before touching everything else.
    
- **Let people experiment with safe, low‑risk AI tools.**  
    Encourage the use of AI writing and brainstorming tools for internal tasks (emails, drafts, summaries) so the team gets comfortable with the idea of AI.
    

---

## 2. The AI‑Curious, Data‑Challenged

**Snapshot:**  
Leadership is talking about AI, staff use ChatGPT on the side, but there’s no formal strategy, and the data is still a mess.

**Typical criteria**

- **Data & systems**
    
    - You have core systems (CRM/ERP, finance, HR), but they’re not well integrated.
        
    - Reporting is mostly manual; people export to Excel and build one‑off dashboards.
        
    - Data quality issues are well known (duplicates, missing fields, conflicting numbers).
        
- **AI usage**
    
    - No live AI use cases, but you’ve had demos from vendors or internal brainstorming sessions.
        
- **People & culture**
    
    - Leadership is curious but vague: “We need to do something with AI.”
        
    - Staff are uncertain how AI applies to their day job.
        
- **Governance**
    
    - No formal AI policy, but some nervousness about security and customer data.
        

**What’s really going on**

- The organisation is **mentally on board** but lacks clarity and confidence.
    
- The biggest pains: not knowing _where to start_, and not trusting the data enough to do anything serious.
    

### What to focus on next

- **Map where your data actually lives.**  
    List your main systems (CRM, ERP, finance, HR, support, website, etc.) and what data each holds. Note where quality is a problem.
    
- **Pick 2–3 concrete business problems, not “AI projects.”**  
    Examples: “Reduce quote turnaround time by 50%” or “Cut invoice errors by 30%.” Anchor everything to a clear business outcome.
    
- **Make those few datasets fit for purpose.**  
    For each chosen problem, clean and tidy the relevant data (consistent IDs, mandatory fields, fewer duplicates). Don’t try to clean everything at once.
    
- **Agree simple rules for using AI tools.**  
    Write a one‑page guideline: what staff can and cannot paste into public AI tools, and what types of tasks they should use them for.
    
- **Form a small, cross‑functional “AI squad.”**  
    Bring together one person from IT, one from operations, and one from a business team. Give them ownership for identifying and shaping your first proper AI use cases.
    

---

## 3. The Pilot‑Heavy, Impact‑Light (“Pilot Purgatory”)

**Snapshot:**  
You’ve run or are running AI pilots – a chatbot here, an RPA bot there – but nothing has scaled or delivered clear ROI.

**Typical criteria**

- **Data & systems**
    
    - Some data pipelines exist; maybe a basic data warehouse or BI tool is in place.
        
    - Pilots rely on bespoke data extracts and manual workarounds rather than robust pipelines.
        
- **AI usage**
    
    - 1–3 pilots (e.g. customer support chatbot, predictive lead scoring, invoice OCR).
        
    - Pilots live in isolated teams and aren’t fully embedded in day‑to‑day workflows.
        
- **People & culture**
    
    - Enthusiasts in pockets (innovation team, IT, one business unit).
        
    - Other teams are sceptical: “This AI thing is a distraction; I still do everything in Excel.”
        
- **Governance & ROI**
    
    - No standard way to evaluate AI projects.
        
    - No clear owner for “AI at the company” — initiatives pop up ad hoc.
        

**What’s really going on**

- You’ve **proved AI can work technically**, but not that it moves the needle for the business.
    
- Integration, change management, and ROI tracking are the big gaps.
    

### What to focus on next

- **Choose one flagship use case to bet on.**  
    From your existing pilots, pick the one with the clearest business value, decent data, and a motivated business owner. Pause or stop weaker pilots.
    
- **Define success in numbers before you scale.**  
    Decide on 1–3 specific metrics (e.g. time saved, error reduction, revenue uplift). Write down the baseline and the target you want to hit.
    
- **Integrate the AI into the real workflow.**  
    Embed the AI into the systems people already use (e.g. CRM, ticketing, ERP) so it becomes part of “how work is done,” not a separate experiment.
    
- **Update processes and responsibilities.**  
    Document how roles change when the AI is in place: who checks outputs, when humans override, and what steps are removed.
    
- **Track and share the results.**  
    Build a simple dashboard or monthly report showing before/after performance. Use that story to build trust and secure support for the next wave.
    

---

## 4. The Emerging Scaler

**Snapshot:**  
You have a few AI use cases in production and a basic data platform, but scaling across the business is slow and messy.

**Typical criteria**

- **Data & systems**
    
    - Central data platform/datamart exists; basic ETL pipelines are live.
        
    - Legacy systems and technical debt still cause integration headaches.
        
- **AI usage**
    
    - 3–10 live AI use cases across different functions (e.g. forecasting, routing, fraud alerts, marketing optimisation).
        
    - Still heavily dependent on a small data/AI team for changes.
        
- **People & culture**
    
    - Leadership is supportive and talking about AI strategically.
        
    - Adoption is uneven: some teams love it; others ignore it or work around it.
        
- **Governance & compliance**
    
    - Side‑of‑desk policies exist, but no consistent approach to risk, bias, or model monitoring.
        

**What’s really going on**

- You’ve shown AI can deliver value, but you’re now facing **scaling friction**:
    
    - Bottlenecks in the data/AI team,
        
    - Inconsistent adoption across units,
        
    - Growing worries about risk and governance.
        

### What to focus on next

- **Create a standard AI project playbook.**  
    Define the stages every AI initiative follows (idea → design → build → test → deploy → monitor) and the checkpoints at each stage.
    
- **Reuse what already works.**  
    Turn common components (data pipelines, integrations, prompts, templates, models) into shared “building blocks” that new projects can plug into.
    
- **Give each business unit an AI champion.**  
    Nominate someone in each key team to collect ideas, support adoption, and act as the link between that team and your data/IT function.
    
- **Invest in practical AI training for users.**  
    Teach managers and frontline staff how to interpret AI outputs, when to trust them, and when to challenge them. Use real examples from your own use cases.
    
- **Classify use cases by risk level.**  
    Separate low‑risk, internal productivity tools from high‑impact, regulated or customer‑facing applications. Apply stricter checks only where they’re genuinely needed.
    

---

## 5. The Strategic Integrator

**Snapshot:**  
AI is part of your core strategy, embedded into multiple processes, and you’re now wrestling with optimisation, governance, and advanced opportunities.

**Typical criteria**

- **Data & systems**
    
    - Mature data platform; near‑real‑time pipelines for key domains.
        
    - Strong integration with line‑of‑business systems; APIs everywhere.
        
- **AI usage**
    
    - Double‑digit AI use cases in production, touching most departments.
        
    - Some custom models, some vendor solutions, some generative AI components.
        
- **People & culture**
    
    - Leadership treats AI as a growth and transformation lever, not a side project.
        
    - Most managers are data‑literate; teams expect to see data/AI support in decision‑making.
        
- **Governance & compliance**
    
    - Formal AI policies, risk assessments, and model monitoring exist.
        
    - Growing focus on fairness, bias, auditability, and external regulations.
        

**What’s really going on**

- You’re past the basics; your challenges are now about **quality, resilience, and responsible scaling**:
    
    - Avoiding model sprawl and duplicated efforts,
        
    - Ensuring consistent governance,
        
    - Prioritising where to invest next.
        

### What to focus on next

- **Map your full AI and analytics portfolio.**  
    List all live and in‑flight use cases. For each, note the owner, business goal, value delivered, and risk level.
    
- **Prune low‑value or redundant solutions.**  
    Retire pilots and tools that aren’t clearly moving a key metric. Reduce duplication by consolidating similar use cases onto shared platforms or models.
    
- **Strengthen Responsible AI practices.**  
    Standardise documentation (model cards, risk assessments) and schedule regular reviews for bias, performance drift, and unexpected side effects.
    
- **Automate more of the AI lifecycle.**  
    Introduce automated testing, monitoring, and retraining triggers so models don’t silently degrade and your team isn’t constantly firefighting.
    
- **Shift some effort from efficiency to innovation.**  
    Dedicate a portion of your AI capacity to exploring new products, services, or customer experiences that wouldn’t exist without AI.
    

---

## 6. The AI‑First / Transformative Leader

**Snapshot:**  
AI is woven into your core value proposition. You’re experimenting at the frontier and thinking about ecosystem, not just internal efficiency.

**Typical criteria**

- **Data & systems**
    
    - Highly advanced data & ML infrastructure; multi‑cloud or hybrid setups.
        
    - Real‑time decisioning in multiple customer or operational journeys.
        
- **AI usage**
    
    - AI is central to your product/service (e.g. recommendations, automation, personalisation, risk scoring, optimisation).
        
    - You build and/or fine‑tune models as a strategic capability, not just consume them.
        
- **People & culture**
    
    - Cross‑functional AI squads are normal; experimentation is baked into culture.
        
    - Strong internal AI brand; you attract and retain specialist talent.
        
- **Governance & compliance**
    
    - Dedicated Responsible AI / AI ethics body or function.
        
    - Proactive engagement with regulators, industry bodies, and customers about AI use.
        

**What’s really going on**

- Your key challenges are **frontier risks and long‑term resilience**:
    
    - Managing technical debt and complexity as the AI estate grows,
        
    - Keeping up with regulation and public expectations,
        
    - Avoiding complacency as competitors catch up.
        


### What to focus on next

- **Continuously simplify and refactor your AI estate.**  
    Identify overlapping tools, models, and platforms. Consolidate where possible and deliberately retire outdated architectures to reduce complexity and risk.
    
- **Turn transparency into a differentiator.**  
    Explain clearly (internally and externally) where and how AI is used, what data it relies on, and what safeguards exist. Make it easy for customers and staff to ask questions or challenge decisions.
    
- **Plan for frontier risks.**  
    Run scenarios for model failure, data breaches, regulatory changes, and reputational incidents. Define playbooks for how you would respond.
    
- **Invest in proprietary data and domain‑specific models.**  
    Focus on data assets and model capabilities that are uniquely hard for competitors to copy and deeply aligned with your niche or industry.
    
- **Look beyond your own organisation.**  
    Explore partnerships, platforms, and ecosystems where your AI capabilities become infrastructure others build on (e.g. APIs, embedded services, co‑developed solutions).
    
